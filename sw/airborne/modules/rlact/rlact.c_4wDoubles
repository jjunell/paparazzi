/*
 * Copyright (C) 2008-2012 The Paparazzi Team
 *
 * This file is part of paparazzi.
 *
 * paparazzi is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2, or (at your option)
 * any later version.
 *
 * paparazzi is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 
 * You should have received a copy of the GNU General Public License
 * along with paparazzi; see the file COPYING.  If not, write to
 * the Free Software Foundation, 59 Temple Place - Suite 330,
 * Boston, MA 02111-1307, USA.
 */
 
 /* This module creates a flight plan callable function to learn high level guidance via reinforcement learning.  written by Jaime Junell */

#include "rlact.h"
#include "generated/airframe.h"
#include <time.h>
#include <stdlib.h>

#include "messages.h"
#include "mcu_periph/uart.h"
#include "subsystems/datalink/downlink.h"
#include "generated/flight_plan.h"  //needed to use WP_HOME

//*************** DECLARE VARIABLES *****************//
// environment and states for RL algorithm
int8_t drow, dcol;
int8_t state_curr, state_next;
int8_t ns_curr, ns_next;//current nectar state 0-5 (base 0)
const int8_t nns = 5;  //last nectar state (base 0)
const int8_t ndim = 6; //number of elements in a dimension = 6 (nrows,ncols, nns)
const int8_t nstates=36; //=ndim*ndim

// flags
int8_t nsflag;  //nectar state flag = nectar full
int8_t hbflag;      //hitbounds flag

// Bellman equation
    double V_old, alphav;
    const double belgam = 0.9;  // gamma for belman equation
    static double V[36][6]= {{0}}; // Value function initialized to zeros
    static int kv[36][6]= {{0}}; // number of times a state has been visited
    static int ka[8]= {0};  //number of times an action has been taken, initialized as 0
	double reward;

// for execution of RL in paparazzi
const int16_t del = 80;// distance to move in each action
static int32_t pass;

// policy decisions - just random for now
const int8_t nact = 8; //number of actions possible (NESW + diagonals)
int8_t act;
int16_t eps;  //eps=0 is random, eps=100 is full greedy.

//*********************** FUNCTIONS ***********************//
void rlact_init(void) {
//initialize variables
printf("init1\n");
	state_curr = 0;
	state_next = 0;
	ns_curr = 0;
	ns_next = 0;
		
	nsflag = 0;
	hbflag = 0;
	
	reward = 0.0;
	
	act= 0; 
	pass=0;
	eps=0;

printf("init2\n");
	srand(time(NULL)); //initialize random number generator just once
printf("init3\n");
  //  const int nact = 4; //number of actions = 4 (NESW)

}

///////*  OWN FUCTION TO CALL FROM FLIGHT PLAN *//////
bool_t rlact_run(uint8_t wpa, uint8_t wpb){
pass++;
// printf("pass = %d\n",pass);

if(pass==1){

	state_curr = 14; //Random state between 0-35;
	drow = state_curr % ndim; // remainder = #increments to move in y from home
	dcol = (int)state_curr/ndim;  // rounded down = #increments to move in x from home
	waypoints[wpb].x = waypoints[WP_p00].x + dcol*del;
	waypoints[wpb].y = waypoints[WP_p00].y + drow*del;
	}
else{
	//act = (rand() % nact);
	act = (pass % nact) + 1; //takes always 1-8 incrementally;
	printf("state = %d, visit# %d, Vold= %.4f, ",state_curr, kv[state_curr][ns_curr],V[state_curr][ns_curr]);
	
	// give rewards for current state and calculate next state
	switch(state_curr){
	case 2 :  case 22 : case 30 : // flowers 
		reward = 8.0;
		ns_next = ns_curr + 1;
		nsflag = 0;
		
			if(ns_next>nns){ //if full of nectar, no reward
				ns_next = nns;
				reward = 0.0;
				nsflag = 1;
			}
			// if action results in out-of-bounds, decrease reward, choose new action
			hbflag = 0;
			while(hbflag){
				reward = reward - 1.0;
				act = 0;
				hbflag =  0;
			}
			
		// calculate next state
		  // if random policy or last nectar state, execute actions
		  // if ep-greedy then randomly generate anywhere on the board
		  if(nsflag || eps==0){  
		  	switch(act){
				case 1: state_next = state_curr + 1; break;    //north
				case 2: state_next = state_curr + ndim; break; //east
				case 3: state_next = state_curr -1; break;     //south
				case 4: state_next = state_curr - ndim; break; //west
				case 5: state_next = state_curr + 1 - ndim; break;  //northwest
				case 6: state_next = state_curr + 1 + ndim; break;  //northeast
				case 7: state_next = state_curr - 1 + ndim; break;  //southeast
				case 8: state_next = state_curr - 1 - ndim; break;  //southwest
			}
		  }
		  else {  //if ep-greedy (eps>0)
		  	state_next = 14; 
		  }
		break;
		
	case 35 :      // if in hive state  
		reward = 0.99*(double)ns_curr*(double)ns_curr;  //hive reward function base 0
		// reset at nectar state 0, and a random grid location.
		ns_next = 0;
		state_next = rand() % nstates;
		act = 9; //special hive implementation for random regeneration
		break;
		
	default :         // not a reward space (code done for random policy)
	// if not in reward spot: check if boundary is hit, if so give negative reward and stay in same state, otherwise, calculate next state and give no reward.
		reward = 0.0;
		ns_next = ns_curr;
		
		hbflag = 0;
		if(hbflag){
			reward = -1.0;
			state_next = state_curr;
			act = 0;  // special action for not moving; (not really a chosen action, but needed for implemention in paparazzi.)
		}
		else{
			switch(act){
				case 1: state_next = state_curr + 1; break;    //north
				case 2: state_next = state_curr + ndim; break; //east
				case 3: state_next = state_curr -1; break;     //south
				case 4: state_next = state_curr - ndim; break; //west
				case 5: state_next = state_curr + 1 - ndim; break;  //northwest
				case 6: state_next = state_curr + 1 + ndim; break;  //northeast
				case 7: state_next = state_curr - 1 + ndim; break;  //southeast
				case 8: state_next = state_curr - 1 - ndim; break;  //southwest
			}
		}
    } // switch statement - reward function
    
    //override stay in same nectar state:
    ns_curr=0; ns_next=0;
    
/* Now with reward and next state calculated:
   1) update value function for current state using belman eqn
   2) take action in paparazzi sim/IRL
   3) reset "next state" to "current state" for next iteration */

    // update Value function
    printf("At grid spot %d, nectar state %d. visited %d times\n",state_curr,ns_curr,kv[state_curr][ns_curr]);
    V_old = V[state_curr][ns_curr];
     ++kv[state_curr][ns_curr];   
     alphav = 1.0/(double)kv[state_curr][ns_curr];
    V[state_curr][ns_curr] = V_old + alphav*(reward + belgam* V[state_next][ns_next] - V_old);
	printf(" Vnew= %.4f\n",V[state_curr][ns_curr]);

    	//execute in paparazzi sim/IRL
	switch (act){
	    case 0: /* no movement */
	    waypoints[wpb].x = waypoints[wpa].x;    
		waypoints[wpb].y = waypoints[wpa].y;
		printf("act = %d\n",act);
		break;
		case 1: /* north */
		waypoints[wpb].x = waypoints[wpa].x;    
		waypoints[wpb].y = waypoints[wpa].y + del;
		printf("act = %d\n",act);
		++ka[0];
		break;
		case 2: /* east */
		waypoints[wpb].x = waypoints[wpa].x + del;
		waypoints[wpb].y = waypoints[wpa].y;
		printf("act = %d\n",act);
		++ka[1];
		break;
		case 3: /* south */
		waypoints[wpb].x = waypoints[wpa].x;
		waypoints[wpb].y = waypoints[wpa].y - del;
		printf("act = %d\n",act);
		++ka[2];
		break;      
		case 4: /* west */
		waypoints[wpb].x = waypoints[wpa].x - del;
		waypoints[wpb].y = waypoints[wpa].y;
		printf("act = %d\n",act);
		++ka[3];
		break;    
		case 5: /* northwest */
		waypoints[wpb].x = waypoints[wpa].x - del;    
		waypoints[wpb].y = waypoints[wpa].y + del;
		printf("act = %d\n",act);
		++ka[4];
		break;
		case 6: /* northeast */
		waypoints[wpb].x = waypoints[wpa].x + del;
		waypoints[wpb].y = waypoints[wpa].y + del;
		printf("act = %d\n",act);
		++ka[5];
		break;
		case 7: /* southeast */
		waypoints[wpb].x = waypoints[wpa].x + del;
		waypoints[wpb].y = waypoints[wpa].y - del;
		printf("act = %d\n",act);
		++ka[6];
		break;      
		case 8: /* southwest */
		waypoints[wpb].x = waypoints[wpa].x - del;
		waypoints[wpb].y = waypoints[wpa].y - del;
		printf("act = %d\n",act);
		++ka[7];
		break;
		case 9:  /* special hive random regeneration */
		drow = state_next % ndim; // remainder = #increments to move in y from home
		dcol = (int)state_next/ndim;  // rounded down = #increments to move in x from home
		waypoints[wpb].x = waypoints[WP_p00].x + dcol*del;
		waypoints[wpb].y = waypoints[WP_p00].y + drow*del;
		printf("act = %d\n",act);
		break;
		default: /* no movement */
	    waypoints[wpb].x = waypoints[wpa].x;
		waypoints[wpb].y = waypoints[wpa].y;
		state_next = state_curr; ns_next = ns_curr;
		printf("default action stay still: no valid action taken\n");
		break;
	}
	
	
  // reset "next state" to "current state" for next iteration
  state_curr = state_next;
  ns_curr = ns_next;	

} //if not first pass

		return FALSE;
}  // end of rlact_run function

